{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Audio2Image\n",
    "\n",
    "Run this notebook to train the model"
   ],
   "id": "81b47289d810c7ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:33:21.654855Z",
     "start_time": "2024-04-23T17:33:15.226393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "!pip install PySoundFile"
   ],
   "id": "9ed6448655234ad0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PySoundFile in c:\\users\\rishav roy\\miniconda3\\lib\\site-packages (0.9.0.post1)\n",
      "Requirement already satisfied: cffi>=0.6 in c:\\users\\rishav roy\\miniconda3\\lib\\site-packages (from PySoundFile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rishav roy\\miniconda3\\lib\\site-packages (from cffi>=0.6->PySoundFile) (2.21)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:33:31.648923Z",
     "start_time": "2024-04-23T17:33:21.657370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ],
   "id": "bcf0a619a1613ad7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Create Dataset and DataLoader",
   "id": "47775be7939979f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:33:31.656453Z",
     "start_time": "2024-04-23T17:33:31.649930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "IMG_TRANSFORM = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256, 256)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ],
   "id": "30bda34acf377236",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:33:31.668027Z",
     "start_time": "2024-04-23T17:33:31.662006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NEW_COLUMN_NAMES = {\n",
    "    '---g-f_I2yQ': 'youtube_video_id',\n",
    "    '1': 'start_seconds',\n",
    "    'people marching': 'label',\n",
    "    'test': 'split',\n",
    "}"
   ],
   "id": "d687d8b775994fc2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:34.451258Z",
     "start_time": "2024-04-23T17:37:34.429243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, audio_dir, img_dir, img_transform=None, embeddings=None):\n",
    "        self.audio_dir = audio_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.img_transform = img_transform\n",
    "        self.embeddings = embeddings\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.rename_columns()\n",
    "        self.add_columns()\n",
    "        self.remove_invalid_rows()\n",
    "\n",
    "    @staticmethod\n",
    "    def check_validity(image_path):\n",
    "        try:\n",
    "            Image.open(image_path)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def remove_invalid_rows(self):\n",
    "        self.df['is_valid'] = self.df['img_path'].apply(AudioDataset.check_validity)\n",
    "        self.df = self.df[self.df['is_valid'] == True]\n",
    "        self.df = self.df.drop(columns=['is_valid'])\n",
    "\n",
    "    def rename_columns(self):\n",
    "        self.df.rename(columns=NEW_COLUMN_NAMES, inplace=True)\n",
    "\n",
    "    def add_columns(self):\n",
    "        self.df['audio_path'] = self.df['youtube_video_id'].apply(\n",
    "            lambda x: self.audio_dir + '/' + 'audio_' + x + '.wav')\n",
    "        self.df['img_path'] = self.df['youtube_video_id'].apply(lambda x: self.img_dir + '/' + 'image_' + x + '.jpg')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(f\"Index = {idx}\")\n",
    "        try:\n",
    "            if torch.is_tensor(idx):\n",
    "                idx = idx.tolist()\n",
    "            else:\n",
    "                idx = [idx]\n",
    "            audio_path = self.df.loc[idx, 'audio_path'].values[0]\n",
    "            waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
    "            transform = torchaudio.transforms.Resample(sample_rate, sample_rate / 10)\n",
    "            waveform = transform(waveform)\n",
    "\n",
    "            label = self.df.loc[idx, 'label'].values[0]\n",
    "\n",
    "            img_path = self.df.loc[idx, 'img_path'].values[0]\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            if self.img_transform is not None:\n",
    "                img = self.img_transform(img)\n",
    "\n",
    "            if self.embeddings is not None:\n",
    "                waveform = self.embeddings(waveform)\n",
    "\n",
    "            return waveform.mean(dim=0), img, label\n",
    "        except:\n",
    "            return None, None, None"
   ],
   "id": "375cfca40a74a166",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:35.057321Z",
     "start_time": "2024-04-23T17:37:35.052130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CSV_FILE = './vggsound.csv'\n",
    "AUDIO_DIR = './data/audio'\n",
    "IMG_DIR = './data/image'"
   ],
   "id": "572ad207ccd47bfd",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:46.457337Z",
     "start_time": "2024-04-23T17:37:35.522443Z"
    }
   },
   "cell_type": "code",
   "source": "audio2image_dataset = AudioDataset(CSV_FILE, AUDIO_DIR, IMG_DIR, IMG_TRANSFORM)",
   "id": "7d92a70d884be8ef",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:46.470112Z",
     "start_time": "2024-04-23T17:37:46.462347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate(batch):\n",
    "    \"\"\"Collate function for the dataloader.\"\"\"\n",
    "    audios, images, labels = zip(*batch)\n",
    "    return (\n",
    "        torch.concat(audios, dim=0),\n",
    "        torch.concat(images, dim=0),\n",
    "        list(labels)\n",
    "    )"
   ],
   "id": "5ed78c84124aa398",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:46.484129Z",
     "start_time": "2024-04-23T17:37:46.474123Z"
    }
   },
   "cell_type": "code",
   "source": "BATCH_SIZE = 1",
   "id": "6939bf8f0085bdb0",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:46.495166Z",
     "start_time": "2024-04-23T17:37:46.485140Z"
    }
   },
   "cell_type": "code",
   "source": "audio2image_dataloader = torch.utils.data.DataLoader(audio2image_dataset, batch_size=BATCH_SIZE, shuffle=True,collate_fn=custom_collate)",
   "id": "3b726065bce5d0e1",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:46.504421Z",
     "start_time": "2024-04-23T17:37:46.498720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# num_workers fails in Windows\n",
    "if os.name != 'nt':\n",
    "    audio2image_dataloader.num_workers = os.cpu_count()"
   ],
   "id": "6e49cb975cb0fc8d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:37:46.563945Z",
     "start_time": "2024-04-23T17:37:46.507964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataiter = iter(audio2image_dataloader)\n",
    "for i in range(2):\n",
    "    waves, pics, texts = next(dataiter)"
   ],
   "id": "8f993c1df0fc9689",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index = 0\n",
      "Index = 3\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a2b777f00b311809"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
