{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d91f0b1-db1c-4c29-88a3-b97a4fc65fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T07:38:25.702739Z",
     "start_time": "2024-04-22T07:38:25.697550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /ext3/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: opencv-python in /home/as18464/.local/lib/python3.12/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: transformers in /ext3/miniconda3/lib/python3.12/site-packages (4.40.0)\n",
      "Requirement already satisfied: matplotlib in /home/as18464/.local/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: filelock in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /ext3/miniconda3/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /ext3/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/as18464/.local/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /ext3/miniconda3/lib/python3.12/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/as18464/.local/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/as18464/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/as18464/.local/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/as18464/.local/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/as18464/.local/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /ext3/miniconda3/lib/python3.12/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /ext3/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /ext3/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ext3/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /ext3/miniconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch opencv-python transformers matplotlib\n",
    "import os\n",
    "\n",
    "import moviepy.editor as mp\n",
    "import pandas as pd\n",
    "import torch\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de456fff-a54b-4f16-af24-dc0dc73356df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:02.969860Z",
     "start_time": "2024-04-22T02:04:02.951058Z"
    }
   },
   "outputs": [],
   "source": [
    "TIME_DURATION_IN_SEC = 10\n",
    "CSV_FILE = './vggsound.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b0dc544-36ab-48eb-8d18-0b2368b7e5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:02.977352Z",
     "start_time": "2024-04-22T02:04:02.972375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "new_column_names = {\n",
    "    '---g-f_I2yQ': 'youtube_video_id',\n",
    "    '1': 'start_seconds',\n",
    "    'people marching': 'label',\n",
    "    'test': 'split',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "176a71bc-47e9-4e72-a02a-5b36ee42aae9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:03.188644Z",
     "start_time": "2024-04-22T02:04:02.977352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "df.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "347bb06b-0b59-4a08-89eb-f1446b65ed31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:03.203712Z",
     "start_time": "2024-04-22T02:04:03.189650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youtube_video_id</th>\n",
       "      <th>start_seconds</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--0PQM4-hqg</td>\n",
       "      <td>30</td>\n",
       "      <td>waterfall burbling</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--56QUhyDQM</td>\n",
       "      <td>185</td>\n",
       "      <td>playing tennis</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--5OkAjCI7g</td>\n",
       "      <td>40</td>\n",
       "      <td>people belly laughing</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--8puiAGLhs</td>\n",
       "      <td>30</td>\n",
       "      <td>car engine starting</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--96EN9NUQM</td>\n",
       "      <td>242</td>\n",
       "      <td>alarm clock ringing</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  youtube_video_id  start_seconds                  label  split\n",
       "0      --0PQM4-hqg             30     waterfall burbling  train\n",
       "1      --56QUhyDQM            185         playing tennis  train\n",
       "2      --5OkAjCI7g             40  people belly laughing  train\n",
       "3      --8puiAGLhs             30    car engine starting  train\n",
       "4      --96EN9NUQM            242    alarm clock ringing  train"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04019008-84bb-4b85-a84e-771ae46fe8cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:03.213679Z",
     "start_time": "2024-04-22T02:04:03.205719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fbf586b-4d8c-466d-b205-02a42912be12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:03.223275Z",
     "start_time": "2024-04-22T02:04:03.215685Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" if device == \"cpu\" else \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fea9e560007eb6e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:03.232280Z",
     "start_time": "2024-04-22T02:04:03.225283Z"
    }
   },
   "outputs": [],
   "source": [
    "CLIP_MODEL_PATH = './data/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "141e2f00-581c-4ba1-b1b1-197dfab90d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:09.153352Z",
     "start_time": "2024-04-22T02:04:03.234457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the CLIP model\n",
    "if not os.path.exists(os.path.join(CLIP_MODEL_PATH, 'clip_model.pt')):\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "    torch.save(model.state_dict(), os.path.join(CLIP_MODEL_PATH, 'clip_model.pt'))\n",
    "else:\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    model.load_state_dict(torch.load(os.path.join(CLIP_MODEL_PATH, 'clip_model.pt')))\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "19045bfc4461d49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:10.135664Z",
     "start_time": "2024-04-22T02:04:09.161363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load CLIP processor\n",
    "if not os.path.exists(os.path.join(CLIP_MODEL_PATH, 'clip_processor')):\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor.save_pretrained(os.path.join(CLIP_MODEL_PATH, 'clip_processor'))\n",
    "else:\n",
    "    processor = CLIPProcessor.from_pretrained(os.path.join(CLIP_MODEL_PATH, 'clip_processor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f81ac5d9-7712-4dd1-bed7-1dc3e2edb182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:10.160772Z",
     "start_time": "2024-04-22T02:04:10.148742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract the best image from a video\n",
    "def extract_best_image(video_path, label, youtube_video_id):\n",
    "    try:\n",
    "        # Load the video\n",
    "        video = mp.VideoFileClip(video_path)\n",
    "        # Extract video frames\n",
    "        step = 10\n",
    "    \n",
    "        frames = [frame for idx, frame in enumerate(video.iter_frames()) if idx % step == 0]\n",
    "        # Preprocess the text label\n",
    "        inputs = processor(text=[label], images=frames, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "        # Calculate the similarity scores between the text label and each frame\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "            best_match_idx = logits_per_image.argmax().item()\n",
    "\n",
    "        # Save the best matching frame as an image\n",
    "        best_frame = frames[best_match_idx]\n",
    "        output_path = f\"./data/image/image_{youtube_video_id}.jpg\"\n",
    "        mp.ImageClip(best_frame).save_frame(output_path)\n",
    "\n",
    "        print(f\")\n",
    "\n",
    "        # Clean up\n",
    "        video.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error while extracting best frame for video: {youtube_video_id}. Message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "956e4216-4db6-44b8-9f09-7a946b8d6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_frame(limit=5):\n",
    "    for index, row in df.iterrows():\n",
    "        if index < limit:\n",
    "            youtube_video_id = row['youtube_video_id']\n",
    "            label = row['label']\n",
    "            video_file_path = f\"./data/video/video_{youtube_video_id}.mp4\"\n",
    "            audio_file_path = f\"./data/audio/audio_{youtube_video_id}.wav\"\n",
    "            if os.path.exists(audio_file_path) and os.path.exists(video_file_path):\n",
    "                extract_best_image(video_file_path, label, youtube_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16104fe6-d258-44df-a539-66bc3086c9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T02:04:45.936337Z",
     "start_time": "2024-04-22T02:04:10.162290Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_best_frame(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1db6c27969412",
   "metadata": {},
   "source": [
    "## Can be performed while fetching the objects from a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df80b924-c123-47a9-bd5f-47ec4d614474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T07:41:23.574822Z",
     "start_time": "2024-04-22T07:41:23.551872Z"
    }
   },
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaabc8544cc9e169",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T07:45:13.439269Z",
     "start_time": "2024-04-22T07:45:12.594091Z"
    }
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, img_name))\n\u001b[1;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m----> 4\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m img_transforms(image)\n\u001b[1;32m      6\u001b[0m inp \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "for img_name in os.listdir(os.path.join('data', 'image')):\n",
    "    img_path = os.path.join(os.path.join('data', 'image', img_name))\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = img_transforms(image)\n",
    "    inp = image.numpy().transpose((1, 2, 0))\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(inp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d89d7146770972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
